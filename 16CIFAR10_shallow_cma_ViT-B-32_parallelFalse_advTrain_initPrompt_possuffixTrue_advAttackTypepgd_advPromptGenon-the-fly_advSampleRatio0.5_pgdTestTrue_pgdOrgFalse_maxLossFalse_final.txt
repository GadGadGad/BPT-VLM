--- Experiment Results Summary ---
Source: 16CIFAR10_shallow_cma_ViT-B-32_parallelFalse_advTrain_initPrompt_possuffixTrue_advAttackTypepgd_advPromptGenon-the-fly_advSampleRatio0.5_pgdTestTrue_pgdOrgFalse_maxLossFalse_final.pth

==================== Key Metrics ====================
Final Clean Accuracy: 0.9158
Final PGD Accuracy: 0.4098
Best Objective Loss Value: 0.004762
  - Maximizing Loss: False
Best Test Clean Accuracy (during run): 0.9161
Best Test PGD Accuracy (during run): 0.4154
Best Train Accuracy (during run): 1.0000
Optimization Time (s): 41164.39
Number of Evals: 25200

==================== Configurations ====================
--- Command Line Arguments ---
{
  "task_name": "CIFAR10",
  "opt": "shallow_cma",
  "parallel": false,
  "backbone": "ViT-B/32",
  "k_shot": 16,
  "pgd_test": true,
  "adv_train": true,
  "pgd_original_prompt": false,
  "initial_prompt_text": "nsek ljsd iofw enjk",
  "learned_prompt_pos": "suffix",
  "pgd_test_epsilon": 0.03137254901960784,
  "pgd_test_alpha": 0.00784313725490196,
  "pgd_test_num_iter": 10,
  "adv_train_epsilon": 0.01568627450980392,
  "adv_train_alpha": 0.00392156862745098,
  "adv_train_num_iter": 10,
  "adv_train_all": false,
  "adv_train_attack_prompt_type": "on-the-fly",
  "adv_train_alpha_text_prompt": 0.01,
  "adv_train_sample_ratio": 0.5,
  "adv_train_attack_type": "pgd",
  "maximize_loss": false
}

--- Full Config Used ---
{
  "backbone": "ViT-B/32",
  "n_prompt_tokens_L": 8,
  "n_prompt_tokens_V": 5,
  "loss_type": "ce",
  "intrinsic_dim_L": 250,
  "intrinsic_dim_V": 250,
  "sigma": 1,
  "k_shot": 16,
  "seed": 42,
  "bound": 0,
  "batch_size": 128,
  "popsize": 30,
  "train_mode": true,
  "DTD": {
    "budget": 36000,
    "test_every": 12
  },
  "UCF-101": {
    "budget": 25200,
    "test_every": 12
  },
  "EuroSAT": {
    "budget": 25200,
    "test_every": 12
  },
  "StanfordCars": {
    "budget": 25200,
    "test_every": 12
  },
  "OxfordPets": {
    "budget": 3600,
    "test_every": 12
  },
  "Food101": {
    "budget": 3600,
    "test_every": 12
  },
  "caltech101": {
    "budget": 3600,
    "test_every": 12
  },
  "SUN397": {
    "budget": 18000,
    "test_every": 12
  },
  "ImageNet": {
    "budget": 14400,
    "test_every": 60
  },
  "CIFAR100": {
    "budget": 25200,
    "test_every": 12
  },
  "CIFAR10": {
    "budget": 25200,
    "test_every": 12
  },
  "CIFAR10_PGD": {
    "budget": 25200,
    "test_every": 12
  },
  "opt_name": "shallow_cma",
  "data_dir": "/kaggle/working/dataset",
  "output_dir": "/kaggle/working/dataset/result",
  "parallel": false,
  "maximize_loss": false,
  "initial_prompt_text": "nsek ljsd iofw enjk",
  "learned_prompt_pos": "suffix",
  "budget": 25200,
  "test_every": 12,
  "pgd": {
    "epsilon": 0.03137254901960784,
    "alpha": 0.00784313725490196,
    "num_iter": 10,
    "enabled": true,
    "original_prompt": false
  },
  "adv_train": {
    "epsilon": 0.01568627450980392,
    "alpha": 0.00392156862745098,
    "num_iter": 10,
    "enabled": true,
    "all_call": false,
    "attack_prompt_type": "on-the-fly",
    "alpha_text_prompt": 0.01,
    "sample_ratio": 0.5,
    "attack_type": "pgd"
  }
}

==================== Saved Tensors & Models ====================
Tensor 'best_prompt_text':
  Shape: torch.Size([8, 512])
  Dtype: torch.float16
Tensor 'best_prompt_image':
  Shape: torch.Size([5, 768])
  Dtype: torch.float16
State Dict 'Linear_L':
  - weight: Tensor(shape=torch.Size([4096, 250]))
State Dict 'Linear_V':
  - weight: Tensor(shape=torch.Size([3840, 250]))

==================== Historical Data (Last 10 Entries) ====================
History 'acc' (len=70): ['0.9161', '0.9148', '0.9148', '0.9148', '0.9148', '0.9120', '0.9140', '0.9157', '0.9147', '0.9158']
History 'acc_pgd' (len=70): ['0.3804', '0.3942', '0.3931', '0.3939', '0.3912', '0.4051', '0.4154', '0.4089', '0.4042', '0.4100']
History 'train_acc' (len=70): ['1.0000', '1.0000', '1.0000', '1.0000', '1.0000', '1.0000', '1.0000', '1.0000', '1.0000', '1.0000']
History 'loss' (len=25200): ['0.005764', '0.005804', '0.005851', '0.007086', '0.005962', '0.007578', '0.005991', '0.005977', '0.005569', '7.522656']

--- End of Summary ---
